<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Attentionâ€”â€”æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶</title>
      <link href="/2019/01/27/attention/"/>
      <url>/2019/01/27/attention/</url>
      
        <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯-Attention-ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯-Attention-ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯ Attention ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯ Attention ï¼Ÿ</h2><p>æˆ‘ä»¬æ¥ä¸€èµ·çœ‹ç€ä¸‹é¢è¿™å¼ å›¾ç‰‡ï¼Œå¹¶ä¸”è¯»ä¸€ä¸‹ä¸‹é¢è¿™å¥è¯ã€‚</p><blockquote><p>ä¸€åªé»„è‰²çš„å°çŒ«å¸¦ç€ä¸€ä¸ªé¹¿è§’å¸½å­è¶´åœ¨æ²™å‘ä¸Šã€‚</p></blockquote><p><img src="/resource/images/cat.png" alt="cat"></p><p>åœ¨è¯»è¿™å¥è¯çš„è¿‡ç¨‹ä¸­ï¼Œä½ çš„æ³¨æ„åŠ›æ˜¯ä¸æ˜¯ä¼šå‘ç”Ÿå˜åŒ–ï¼Ÿæˆ‘ç›¸ä¿¡å¤§å¤šæ•°äººæ˜¯è¿™æ ·çš„ï¼šå½“è¯»åˆ°â€œå°çŒ«â€çš„æ—¶å€™ï¼Œæ³¨æ„åŠ›åœ¨çŒ«èº«ä¸Šï¼›å½“è¯»åˆ°â€œé¹¿è§’å¸½å­â€çš„æ—¶å€™ï¼Œæ³¨æ„åŠ›åœ¨é¹¿è§’å¸½å­ä¸Šã€‚</p><p>è¿™å°±æ˜¯äººç±»çš„æ³¨æ„åŠ›ï¼Œå®ƒæ˜¯ä¼šéšç€æ—¶é—´å‘ç”Ÿå˜åŒ–çš„ã€‚</p><a id="more"></a><h2 id="ç¥ç»ç½‘ç»œä¸­çš„-Attention-æœºåˆ¶"><a href="#ç¥ç»ç½‘ç»œä¸­çš„-Attention-æœºåˆ¶" class="headerlink" title="ç¥ç»ç½‘ç»œä¸­çš„ Attention æœºåˆ¶"></a>ç¥ç»ç½‘ç»œä¸­çš„ Attention æœºåˆ¶</h2><h3 id="seq2seq-æ¨¡å‹"><a href="#seq2seq-æ¨¡å‹" class="headerlink" title="seq2seq æ¨¡å‹"></a>seq2seq æ¨¡å‹</h3><p><img src="/resource/images/seq2seq.png" alt="seq2seq"></p><p>seq2seq æ˜¯æŒ‡ sequence to sequenceï¼Œè¿™ç±»æ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€ä¸ªåºåˆ— x1ã€x2ã€x3 â€¦ï¼Œè¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ªåºåˆ— y1ã€y2 â€¦ã€‚å®ƒé€šå¸¸ç”±ä¸¤ä¸ªç±»ä¼¼äº LSTM çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰æ„æˆï¼Œä¹Ÿå¸¸è¢«ç§°ä½œ Encoder-Decoder æ¨¡å‹ï¼Œç¬¬ä¸€ä¸ª RNN è¿›è¡Œ encodeï¼Œç¬¬äºŒä¸ª RNN ä½œä¸º decodeã€‚</p><p>ä¸€èˆ¬çš„ Encoder-Decoder æ¨¡å‹ï¼ŒEncoderé˜¶æ®µå¯ä»¥è¡¨ç¤ºä¸ºï¼š</p><p>$$<br>\begin{aligned}<br>    h_t =&amp; f(x_t, h_{t-1}) \\<br>    c   =&amp; q(h_1, â€¦ ,h_T) \\<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼š $h_t$ æ˜¯ n ç»´å®æ•°å‘é‡ï¼Œè¡¨ç¤ºç¼–ç é˜¶æ®µRNNçš„ t æ—¶åˆ»çš„éšè—çŠ¶æ€ï¼›c æ˜¯å„ä¸ªæ—¶åˆ»éšè—çŠ¶æ€ç”Ÿæˆçš„å‘é‡ï¼›ğ‘“ å’Œ ğ‘ æ˜¯éçº¿æ€§å‡½æ•°ã€‚ä¾‹å¦‚ï¼š$f$ å¯ä»¥æ˜¯ LSTMï¼Œ$q$ å‡½æ•°å–æœ€åä¸€ä¸ªæ—¶åˆ»çš„è¾“å‡ºç»“æœï¼Œ$q({h_1, â€¦ ,h_{T_x}}) = h_T$ ã€‚</p><p>Decoder é˜¶æ®µå¯ä»¥è¡¨ç¤ºä¸ºï¼š</p><p>$$<br>\begin{aligned}<br>    y_t =&amp; g(y_{t-1}, s_t, c) \\<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼Œ $y_t$ æ˜¯ t æ—¶åˆ»çš„è¾“å‡ºç»“æœï¼Œåˆå§‹åŒ– $y_0$ ä¸ºé›¶å‘é‡ï¼Œ$s_t$ ä¸º t æ—¶åˆ»éšè—å±‚çŠ¶æ€ï¼Œc ä¸º Encoder é˜¶æ®µçš„è¾“å‡ºç»“æœï¼›g æ˜¯éçº¿æ€§å‡½æ•°ã€‚ä¾‹å¦‚ï¼šg æ˜¯ä¸€ä¸ª LSTM å•å…ƒï¼ŒæŠŠ $y_{t-1}ï¼Œ c$ æ‹¼èµ·æ¥å½“åšè¾“å…¥ã€‚</p><p>åœ¨æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆç­‰åœºæ™¯ä¸­ç»å¸¸ä¼šç”¨åˆ°è¿™ç±»æ¨¡å‹ï¼Œä½†è¿™ç±»æ¨¡å‹æ˜¯æœ‰ä¸€äº›å±€é™æ€§çš„ã€‚</p><ul><li>å±€é™æ€§ï¼šç¼–ç å’Œè§£ç ä¹‹é—´çš„å”¯ä¸€è”ç³»å°±æ˜¯ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¯­ä¹‰å‘é‡ C ï¼›åœ¨è¾“å…¥åºåˆ—è¾ƒé•¿çš„æƒ…å†µä¸‹ä¿¡æ¯æŸå¤±æ›´åŠ ä¸¥é‡ã€‚</li></ul><h3 id="Attention-æ¨¡å‹åŸç†"><a href="#Attention-æ¨¡å‹åŸç†" class="headerlink" title="Attention æ¨¡å‹åŸç†"></a>Attention æ¨¡å‹åŸç†</h3><p>ç”±äºå•çº¯çš„seq2seqä¼šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œäºæ˜¯äººç±»ä¾¿å‘æ˜åœ¨ç¥ç»ç½‘ç»œåŠ å…¥æ¨¡æ‹Ÿäººç±»æ³¨æ„åŠ›çš„æœºåˆ¶ã€‚</p><p>ä¸‹é¢æˆ‘ä»¬ä¸ºä¸Šé¢çš„ Encoder-Decoder æ¨¡å‹åŠ å…¥ä¸€ç§ Attention æœºåˆ¶ã€‚</p><p>Attention æœºåˆ¶æ”¹å˜çš„æ˜¯ Encoder-Decoder æ¨¡å‹ä¸­çš„ Decoder é˜¶æ®µï¼›Encoder é˜¶æ®µä¸å˜ï¼Œå°† Decoder é˜¶æ®µå˜æˆï¼š</p><p>$$<br>\begin{aligned}<br>    y_t =&amp; g(y_{t-1}, s_t, c_t)<br>\end{aligned}<br>$$</p><p>å•ä¸€å‘é‡ c å˜æˆäº†ä¸€ç»„å‘é‡ $c_t$ ï¼Œå®ƒçš„è®¡ç®—æ–¹å¼ä¸ºï¼š</p><p>$$<br>c_t = \sum_j^T{\alpha_{tj} h_j}<br>$$</p><p>å…¶ä¸­ï¼Œ $h_j \in {(h_1, â€¦ ,h_T)}$ ï¼Œå³ $h_j$ ä¸ºEncoderé˜¶æ®µjæ—¶åˆ»çš„è¾“å‡ºï¼Œ$\alpha_{tj}$ ä¸ºtæ—¶åˆ»ç¬¬jä¸ªéšè—å±‚çš„æƒé‡ç³»æ•°ï¼Œå®ƒå¯ä»¥é€šè¿‡ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œå­¦ä¹ å¾—åˆ°ï¼š</p><p>$$<br>\begin{aligned}<br>    c_{tj} = \frac{\rm{exp}(e_{tj})} {\sum_{k=1}^T{ \rm{exp}(e_{tk}) }} \\<br>    e_{tj} = a(s_{t-1}, h_j)<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼Œğ‘ æ˜¯ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼Œæ¯”å¦‚ï¼šğ‘ å¯ä»¥æ˜¯ä¸€ä¸ªç”± tanh ä½œä¸ºæ¿€æ´»å‡½æ•°çš„ç¥ç»å…ƒã€‚$s_{t-1}$ ä¸ºt-1æ—¶åˆ»çš„decoderé˜¶æ®µçš„éšè—å±‚çŠ¶æ€ï¼Œ$h_j$ encoder é˜¶æ®µ j æ—¶åˆ»çš„è¾“å‡ºã€‚</p><p>æ€»çš„æ¥è¯´å°±æ˜¯ï¼š</p><blockquote><p>t æ—¶åˆ»çš„å‘é‡ $c_t$ æ˜¯ç”±encoderé˜¶æ®µå„ä¸ªæ—¶åˆ»çš„è¾“å‡º $h_t$ åŠ æƒå¾—åˆ°çš„ç»“æœï¼›<br>è€Œè¿™ä¸ªåŠ æƒçš„æƒé‡æ˜¯ç”±decoderé˜¶æ®µt-1æ—¶åˆ»çš„éšè—å±‚çŠ¶æ€ $s_{t-1}$ å’Œencoderé˜¶æ®µå„ä¸ªæ—¶åˆ»çš„è¾“å‡º $h_t$ é€šè¿‡ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œå¹¶å½’ä¸€åŒ–ä¹‹åçš„ç»“æœã€‚</p></blockquote><h3 id="Attention-æœºåˆ¶å¯è§†åŒ–"><a href="#Attention-æœºåˆ¶å¯è§†åŒ–" class="headerlink" title="Attention æœºåˆ¶å¯è§†åŒ–"></a>Attention æœºåˆ¶å¯è§†åŒ–</h3><p><img src="/resource/images/attention-1.png" alt="attention model"></p><p>å›¾ä¸­ï¼Œæ¨ªè½´ä¸ºï¼šè¾“å…¥çš„è‹±æ–‡å•è¯åºåˆ—ï¼Œçºµè½´ä¸ºï¼šè¾“å‡ºçš„æ³•è¯­å•è¯åºåˆ—ï¼›æ¯ä¸€è¡Œæ˜¯æƒå€¼ ğ›¼ ç»„æˆçš„å‘é‡ï¼›è¶Šäº®çš„åœ°æ–¹æƒé‡è¶Šå¤§ã€‚</p><p>è¿™ç›¸å½“äºå®ç°äº†ä¸€ç§ â€œè½¯å¯¹é½â€ æœºåˆ¶ï¼Œæ‰€ä»¥æ³¨æ„åŠ›æœºåˆ¶æœ‰æ—¶ä¹Ÿå«åš â€œå¯¹é½æ¨¡å‹â€ ï¼ˆAlignment Modelï¼‰ã€‚</p><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><p><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">https://arxiv.org/abs/1409.0473</a><br><a href="https://mp.weixin.qq.com/s/_Ru6GMcrSO25bTs8vM6FmA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/_Ru6GMcrSO25bTs8vM6FmA</a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>LSTM</title>
      <link href="/2019/01/19/LSTM/"/>
      <url>/2019/01/19/LSTM/</url>
      
        <content type="html"><![CDATA[<h2 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h2><p>LSTMå…¨ç§°æ˜¯ Long Short Term Memory Networkï¼ˆé•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼‰ï¼Œå®ƒä¹Ÿæ˜¯ä¸€ç§å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ç®—æ³•ã€‚</p><a id="more"></a><p>åœ¨æ™®é€šçš„ RNN ä¸­ï¼Œç»å¸¸ä¼šå‡ºç°ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š</p><ul><li>æ¢¯åº¦çˆ†ç‚¸ï¼šæ¢¯åº¦å¤ªå¤§å¯¼è‡´ç¨‹åºå‡ºé”™</li><li>æ¢¯åº¦æ¶ˆå¤±ï¼šåŸå§‹RNNæ— æ³•å¤„ç†é•¿è·ç¦»ä¾èµ–</li></ul><p>æ¢¯åº¦çˆ†ç‚¸ç›¸å¯¹æ¥è¯´æ¯”è¾ƒå¥½è§£å†³ï¼Œæ¯”å¦‚ï¼šå¯ä»¥è®¾ç½®ä¸€ä¸ªæ¢¯åº¦é˜ˆå€¼ï¼Œå½“æ¢¯åº¦è¶…è¿‡è¿™ä¸ªé˜ˆå€¼çš„æ—¶å€™å¯ä»¥ç›´æ¥æˆªå–ã€‚è€Œç›¸å¯¹äºæ¢¯åº¦æ¶ˆå¤±æ¥è¯´ï¼Œè¿™ä¸ªä¼šæ¯”è¾ƒéš¾è§£å†³ä¸€äº›ã€‚</p><p>LSTM ç®—æ³•çš„å‡ºç°å°±æ˜¯ä¸ºäº†è§£å†³æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ã€‚</p><h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¸ºäº†è§£å†³ RNN æ¨¡å‹ä¸­é•¿è·ç¦»ä¾èµ–æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼ŒLSTM ä¸­å¼•å…¥äº†ä¸€ä¸ªæ–°çš„è®°å¿†å•å…ƒï¼Œä»¥åŠä¸‰ä¸ªé—¨ï¼šè¾“å…¥é—¨ã€é—å¿˜é—¨å’Œè¾“å‡ºé—¨ã€‚</p><p>æ‰€æœ‰é—¨ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°éƒ½æ˜¯sigmoidå‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸‰ä¸ªé—¨çš„å‘é‡ä¸­çš„å…ƒç´ çš„å€¼éƒ½åœ¨ï¼ˆ0, 1ï¼‰ä¹‹é—´ï¼Œä¸‰ä¸ªé—¨çš„ä½œç”¨å¯ä»¥ç†è§£ä¸ºï¼š</p><blockquote><p>è¾“å…¥é—¨ï¼šæ§åˆ¶å½“å‰æ—¶åˆ»çš„è¾“å…¥ï¼Œå†³å®šéœ€è¦å¸æ”¶å½“å‰å¤šå°‘æ¯”ä¾‹çš„è¾“å…¥<br>é—å¿˜é—¨ï¼šæ§åˆ¶é•¿æœŸè®°å¿†çš„é—å¿˜æ¯”ä¾‹ï¼Œå†³å®šæœ‰å¤šå°‘â€œè®°å¿†â€è¢«ä¿ç•™ï¼Œæœ‰å¤šå°‘è¢«é—å¿˜<br>è¾“å‡ºé—¨ï¼šæ§åˆ¶å½“å‰æ—¶åˆ»çš„è¾“å‡ºï¼Œå†³å®šå½“å‰æ—¶åˆ»çš„ç»“æœéœ€è¦è¾“å‡ºå¤šå°‘</p></blockquote><h3 id="å‰å‘è®¡ç®—"><a href="#å‰å‘è®¡ç®—" class="headerlink" title="å‰å‘è®¡ç®—"></a>å‰å‘è®¡ç®—</h3><p><img src="/resource/images/lstm-cell.png" alt="lstm cell"></p><p>$$<br>\begin{aligned}<br>i_t =&amp; \sigma(W_{ii}x_t + W_{hi}h_{t-1} + b_i) \\<br>f_t =&amp; \sigma(W_{if}x_t + W_{hf}h_{t-1} + b_f) \\<br>o_t =&amp; \sigma(W_{io}x_t + W_{ho}h_{t-1} + b_o) \\<br>g_t =&amp; \tanh(W_{ig}x_t + W_{hg}h_{t-1} + b_g) \\<br>c_t =&amp; f_t \times c_{t-1} + i_t \times g_t \\<br>h_t =&amp; o_t \times \tanh c_t \\<br>\end{aligned}<br>$$</p><p>åœ¨ä¸Šå›¾å’Œå…¬å¼ä¸­ï¼Œ$i_t, f_t, o_t$ åˆ†åˆ«ä¸ºè¾“å…¥ã€é—å¿˜ã€è¾“å‡ºé—¨ï¼› $g_t$ ï¼ˆå›¾ä¸­ä¸º$c^\prime_i$ï¼‰æ˜¯å½“å‰æ—¶åˆ»å‰é¦ˆè®¡ç®—çš„ç»“æœï¼› $c_t$ æ˜¯é•¿æœŸè®°å¿†å•å…ƒï¼Œ $h_t$ æ˜¯è¿™ä¸€ä¸ªæ—¶åˆ» LSTM ç½‘ç»œçš„è¾“å‡ºç»“æœã€‚$\sigma$ æ˜¯ sigmoid æ¿€æ´»å‡½æ•°ï¼Œ$\times$ æ˜¯æŒ‡å‘é‡çš„å¯¹åº”å€¼ç›¸ä¹˜ã€‚</p><h3 id="æ¢¯åº¦è®¡ç®—"><a href="#æ¢¯åº¦è®¡ç®—" class="headerlink" title="æ¢¯åº¦è®¡ç®—"></a>æ¢¯åº¦è®¡ç®—</h3><p>LSTM çš„æ¢¯åº¦è®¡ç®—å’Œ RNN çš„å·®ä¸å¤šï¼Œåªæ˜¯å¤šäº†ä¸€äº›å‚æ•°å¤æ‚ä¸€äº›ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥çš„æ–¹æ³•æ¥æ£€éªŒè®¡ç®—çš„æ¢¯åº¦æ˜¯å¦æ­£ç¡®ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p><a href="https://github.com/hf136/models/tree/master/LSTM" target="_blank" rel="noopener">å®Œæ•´ä»£ç </a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networkï¼‰</title>
      <link href="/2018/12/28/rnn/"/>
      <url>/2018/12/28/rnn/</url>
      
        <content type="html"><![CDATA[<h2 id="ç®€ä»‹"><a href="#ç®€ä»‹" class="headerlink" title="ç®€ä»‹"></a>ç®€ä»‹</h2><p>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­ï¼Œéœ€è¦å¤„ç†çš„æ•°æ®é€šå¸¸éƒ½æ˜¯ä¸å®šé•¿çš„ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå°†ä¸‹é¢è¿™ä¸¤å¥è¯ç¿»è¯‘æˆè‹±æ–‡ï¼š</p><ul><li>è¿™ä¸€ä¸–è¯ºè¨€ä»ä¸æ›¾å¿˜ã€‚</li><li>æ·±åº¦å­¦ä¹ çš„æ¦‚å¿µæºäºäººå·¥ç¥ç»ç½‘ç»œçš„ç ”ç©¶ã€‚</li></ul><p>è¿™ä¸¤å¥è¯çš„é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ï¼Œä¸€èˆ¬çš„ç¥ç»ç½‘ç»œè¾“å…¥çš„ç‰¹å¾çº¬åº¦æ˜¯å›ºå®šçš„ï¼Œæ˜¾ç„¶ä¸èƒ½å¾ˆå¥½çš„è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œäºæ˜¯ä¾¿å‡ºç°äº†å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networkï¼ŒRNNï¼‰ã€‚</p><h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><h3 id="åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œ"><a href="#åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œ" class="headerlink" title="åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œ"></a>åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œ</h3><p>ä¸€ä¸ªæœ€åŸºæœ¬çš„å¾ªç¯ç¥ç»ç½‘ç»œç”±è¾“å…¥å±‚ï¼Œéšè—å±‚å’Œè¾“å‡ºå±‚æ„æˆï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/resource/images/rnn-1.jpg" alt="rnn-1"></p><a id="more"></a><p>è¿™é‡Œçš„xã€sã€oåˆ†åˆ«æ˜¯è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ï¼Œå®ƒä»¬éƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼›Wã€Uã€Væ˜¯è¿æ¥å±‚ä¸å±‚ä¹‹é—´çš„æƒé‡çŸ©é˜µã€‚<br>RNNå’Œä¸€èˆ¬çš„ç¥ç»ç½‘ç»œæœ€å¤§ä¸åŒåœ¨äºï¼š</p><blockquote><p>RNNå¤šäº†ä¸€ä¸ªä»éšè—å±‚åˆ°éšè—å±‚($s =&gt; s$)çš„è¿‡ç¨‹ï¼Œä½¿RNNæ‹¥æœ‰äº†â€œè®°å¿†â€çš„åŠŸèƒ½ã€‚<br>(æ³¨æ„ï¼šè¿™é‡Œçš„sè¦æŠŠä»–å®ƒçœ‹å±‚å¤šä¸ªéšè—å±‚çš„å¤šä¸ªç¥ç»å•å…ƒï¼Œsæ˜¯éšè—å±‚å•å…ƒæ„æˆçš„å‘é‡)</p></blockquote><p>åœ¨RNNç½‘ç»œä¸­ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥ä¸€ä¸ªæ—¶é—´ï¼ˆé¡ºåºï¼‰çš„æ¦‚å¿µï¼Œæˆ‘ä»¬æŠŠä¸Šå›¾å±•å¼€ï¼ŒRNNå¯ä»¥ç”»æˆè¿™æ ·ï¼š</p><p><img src="/resource/images/rnn-2.jpg" alt="rnn-2"></p><p>ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œt æ—¶åˆ»çš„RNNç½‘ç»œè¾“å…¥å€¼æ˜¯ $x_t$ï¼Œè¾“å‡ºå€¼æ˜¯ $o_t$ï¼Œéšè—å±‚çš„å€¼æ˜¯ $s_t$ï¼Œå®ƒçš„å€¼å–å†³äºè¾“å…¥å€¼ $x_t$ å’Œ t-1 æ—¶åˆ»çš„éšè—å±‚çš„å€¼ $s_{t-1}$ã€‚</p><h3 id="å‰å‘è®¡ç®—"><a href="#å‰å‘è®¡ç®—" class="headerlink" title="å‰å‘è®¡ç®—"></a>å‰å‘è®¡ç®—</h3><p>RNNçš„æ¯æ—¶é—´æ­¥çš„è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š<br>$$<br>\begin{aligned}<br>s_t =&amp; g(Ux_t + Ws_{t-1} + b) \\<br>o_t =&amp; f(Vs_t)<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼Œgã€f æ˜¯æ¿€æ´»å‡½æ•°ï¼Œs ä¸ºéšè—å±‚çš„å€¼ï¼Œ b æ˜¯åå·®é¡¹ï¼›éšè—å±‚ s çš„åˆå§‹å€¼ $s_0$ ä¸ºé›¶å‘é‡ã€‚</p><p>å¯ä»¥çœ‹å‡ºï¼ŒRNNç½‘ç»œæœ€åè¾“å‡ºçš„ç»“æœå—åˆ°æ‰€æœ‰è¾“å…¥åºåˆ— $x_1, x_2 â€¦ x_T$ çš„å½±å“ã€‚å› ä¸ºéšè— $s_{t-1}$ ä¿å­˜äº†å‰é¢ t-1 ä¸ª x å€¼çš„ç»“æœï¼Œéšè—å±‚ s å……å½“äº†ä¸€ä¸ªâ€œè®°å¿†â€çš„è§’è‰²ã€‚</p><h3 id="ä¼˜åŒ–ç›®æ ‡"><a href="#ä¼˜åŒ–ç›®æ ‡" class="headerlink" title="ä¼˜åŒ–ç›®æ ‡"></a>ä¼˜åŒ–ç›®æ ‡</h3><p>åŒæ ·æ˜¯æ±‚ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„æƒé‡ U ã€ W ã€V ã€bï¼›æŸå¤±å‡½æ•°çš„å½¢å¼æ ¹æ®å…·ä½“çš„ä»»åŠ¡ä¼šæœ‰æ‰€ä¸åŒã€‚</p><h3 id="æ¢¯åº¦è®¡ç®—"><a href="#æ¢¯åº¦è®¡ç®—" class="headerlink" title="æ¢¯åº¦è®¡ç®—"></a>æ¢¯åº¦è®¡ç®—</h3><p>è¿™é‡ŒRNNä½¿ç”¨åˆ°çš„è®¡ç®—æ¢¯åº¦çš„ç®—æ³•æ˜¯BPTTï¼ˆBack Propagation Trough Timeï¼‰ï¼ŒåŠ ä¸Šäº†æ—¶é—´çš„æ¦‚å¿µï¼Œæ˜¯ä¸€ç§åŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ç®—æ³•ã€‚</p><p>è™½ç„¶åå­—å¬ä¸Šå»å¾ˆé«˜å¤§ä¸Šçš„æ ·å­ï¼Œä½†å…¶å®å¹¶ä¸å¤æ‚ï¼Œå’Œæ™®é€šçš„åå‘ä¼ æ’­ç®—æ³•ä¹Ÿå·®ä¸å¤šï¼ŒæŠŠRNNå±•å¼€ä¹‹åï¼Œä¸€æ ·å¯ä»¥ä½¿ç”¨é“¾å¼æ±‚å¯¼ï¼Œè¿™å…¶å®å°±å¾ˆç®€å•äº†ã€‚</p><p><img src="/resource/images/rnn-3.png" alt="RNN backward"></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒæŠŠ RNN å±•å¼€ä¹‹åï¼ŒRNN æ¯ä¸€æ—¶åˆ»çš„åå‘ä¼ æ’­æ±‚å¯¼è¿‡ç¨‹å’Œæ™®é€šçš„ç¥ç»ç½‘ç»œæ˜¯ä¸€æ ·ã€‚æ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼Œæœ‰å¯èƒ½æ¯ä¸€ä¸ªæ—¶åˆ»éƒ½æœ‰è¯¯å·®ä¼ é€’ï¼Œä¹Ÿå¯èƒ½åªæœ‰æœ€åä¸€ä¸ªæ—¶åˆ»æœ‰è¯¯å·®ä¼ é€’ã€‚</p><p>å±•å¼€åçš„ RNN å¯ä»¥çœ‹æˆå…±äº«æƒé‡çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œåªè¦ä½¿ç”¨é“¾å¼æ±‚å¯¼åˆ†åˆ«æ±‚å‡ºæ¯ä¸€ä¸ªæ—¶åˆ»çš„æƒé‡æ¢¯åº¦ï¼Œæœ€åå†æŠŠæ‰€æœ‰æ—¶åˆ»çš„æ¢¯åº¦ç›¸åŠ æ±‚å’Œå°±å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„ RNN æƒé‡æ¢¯åº¦ã€‚</p><h2 id="æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±"><a href="#æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±" class="headerlink" title="æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±"></a>æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±</h2><p>åœ¨åºåˆ—å¾ˆé•¿çš„æ—¶å€™ï¼ŒRNN æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¾ˆå®¹æ˜“å‡ºç°æ¢¯åº¦çˆ†ç‚¸ï¼ˆæ¢¯åº¦å¾ˆå¤§ï¼‰æˆ–è€…æ¢¯åº¦æ¶ˆå¤±ï¼ˆæ¢¯åº¦å‡ ä¹ä¸º0ï¼‰çš„é—®é¢˜ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æ­£å¸¸æ‹Ÿåˆã€‚</p><p>è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ</p><p>é“¾å¼æ±‚å¯¼æ±‚è§£æ¢¯åº¦çš„è¿‡ç¨‹å…¶å®ä¸€ä¸ªè¿ä¹˜çš„è¿‡ç¨‹ï¼š<br>$$<br>\frac{\partial{S_n}}{\partial{S_{n-1}}} \frac{\partial{S_{n-1}}}{\partial{S_{n-2}}} â€¦ \frac{\partial{S_2}}{\partial{S_1}}<br>$$<br>å½“åºåˆ—å¾ˆé•¿çš„æ—¶å€™ï¼Œå¦‚æœæ¯ä¸ªé˜¶æ®µæ¢¯åº¦éƒ½å¤§äº1çš„è¯ï¼Œæ¢¯åº¦å°±ä¼šçˆ†ç‚¸ï¼Œæ¯”å¦‚: $10^9$ ï¼›å¦‚æœæ¯ä¸ªé˜¶æ®µæ¢¯åº¦éƒ½å°äº1çš„è¯ï¼Œæ¢¯åº¦å°±ä¼šæ¶ˆå¤±ï¼Œæ¯”å¦‚: $0.1^9$ ï¼›</p><p>å¯¹äºæ¢¯åº¦æ¶ˆå¤±ï¼Œå…¶å®æŒ‡çš„æ˜¯é•¿è·ç¦»çš„æ¢¯åº¦æ¶ˆå¤±ï¼Œå³é•¿è·ç¦»ä¾èµ–ä¼šæ¶ˆå¤±ï¼Œè®­ç»ƒæ—¶æ¢¯åº¦ä¸èƒ½åœ¨è¾ƒé•¿åºåˆ—ä¸­ä¸€ç›´ä¼ é€’ä¸‹å»ï¼Œä»è€Œä½¿RNNæ— æ³•æ•æ‰åˆ°é•¿è·ç¦»çš„å½±å“ã€‚ä¹Ÿå°±æ˜¯è¯´ RNN çš„â€œè®°å¿†åŠ›â€æœ‰é™ï¼Œåœ¨å¤„ç†è¾ƒé•¿çš„åºåˆ—æ—¶ï¼Œå¾€å¾€ä¼šâ€œå¿˜è®°â€åºåˆ—å‰é¢çš„å†…å®¹ã€‚ç”±äºæ•´ä¸ªæ¨¡å‹çš„æ¢¯åº¦æ˜¯å„ä¸ªæ—¶åˆ»æ¢¯åº¦ä¹‹å’Œï¼Œæ‰€ä»¥æ•´ä¸ªæ¨¡å‹çš„æ¢¯åº¦è¿˜ä¸ä¼šæ¶ˆå¤±ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>è¿™é‡Œå®ç°äº†ä¸€ä¸ªç®€å•çš„ RNN æ¨¡å‹ï¼Œå…¶ä¸­æ¿€æ´»å‡½æ•°ä½¿ç”¨çš„æ˜¯ Relu æ¿€æ´»å‡½æ•°ã€‚<a href="https://github.com/hf136/models/tree/master/RNN" target="_blank" rel="noopener">å®Œæ•´ä»£ç </a></p><p>ä¸€ä¸ª RNN æ—¶é—´æ­¥çš„è®¡ç®—è¿‡ç¨‹ï¼Œå…¶å®å°±å’Œæ™®é€šçš„ç¥ç»ç½‘ç»œæ˜¯ä¸€è‡´çš„ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNNCell</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    ä¸€ä¸ª RNN æ—¶é—´æ­¥çš„è®¡ç®—è¿‡ç¨‹</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_size, hidden_size)</span>:</span></span><br><span class="line">        self.in_size = in_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.w_i2h = np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, (in_size, hidden_size))</span><br><span class="line">        self.w_h2h = np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, (hidden_size, hidden_size))</span><br><span class="line">        self.bias = np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, (<span class="number">1</span>, hidden_size))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x[x &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, h)</span>:</span></span><br><span class="line">        self.i2h = x.dot(self.w_i2h)</span><br><span class="line">        self.h2h = h.dot(self.w_h2h)</span><br><span class="line">        self.h_relu = self.relu(self.i2h + self.h2h + self.bias)</span><br><span class="line">        <span class="keyword">return</span> self.h_relu</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, grad, i, h)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> i.ndim == <span class="number">1</span>:</span><br><span class="line">            i = np.expand_dims(i, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> h.ndim == <span class="number">1</span>:</span><br><span class="line">            h = np.expand_dims(h, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        self.grad_h_relu = grad</span><br><span class="line">        self.grad_h = self.grad_h_relu.copy()</span><br><span class="line">        self.grad_h[h &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        self.grad_w_h2h = h.T.dot(self.grad_h)</span><br><span class="line">        self.grad_w_i2h = i.T.dot(self.grad_h)</span><br><span class="line">        self.grad_bias = self.grad_h</span><br><span class="line">        self.grad_h_in = self.grad_h.dot(self.w_h2h.T)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.grad_h_in</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_weight</span><span class="params">(self, lr)</span>:</span></span><br><span class="line">        self.w_i2h -= lr * self.grad_w_i2h</span><br><span class="line">        self.w_h2h -= lr * self.grad_w_h2h</span><br><span class="line">        self.bias -= lr * self.grad_bias</span><br></pre></td></tr></table></figure><p>å®Œæ•´çš„ RNN åºåˆ—è®¡ç®—è¿‡ç¨‹ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    å®Œæ•´çš„ RNN åºåˆ—è®¡ç®—è¿‡ç¨‹</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_size, hidden_size)</span>:</span></span><br><span class="line">        self.h_state = []</span><br><span class="line">        self.in_size = in_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.rnncell = RNNCell(in_size, hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.h_state = []</span><br><span class="line">        self.x = x</span><br><span class="line">        h = np.zeros(self.hidden_size)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">            self.h_state.append(h)</span><br><span class="line">            h = self.rnncell.forward(i, h)</span><br><span class="line">        self.h_out = h</span><br><span class="line">        <span class="keyword">return</span> self.h_out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, grad)</span>:</span></span><br><span class="line">        self.grad_w_i2h = np.zeros((self.in_size, self.hidden_size))</span><br><span class="line">        self.grad_w_h2h = np.zeros((self.hidden_size, self.hidden_size))</span><br><span class="line">        self.grad_bias = np.zeros((<span class="number">1</span>, self.hidden_size))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.h_state) - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">            x = self.x[i]</span><br><span class="line">            h = self.h_state[i]</span><br><span class="line">            grad = self.rnncell.backward(grad, x, h)</span><br><span class="line">            self.grad_w_i2h += self.rnncell.grad_w_i2h</span><br><span class="line">            self.grad_w_h2h += self.rnncell.grad_w_h2h</span><br><span class="line">            self.grad_bias += self.rnncell.grad_bias</span><br><span class="line">        <span class="keyword">return</span> grad</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_weight</span><span class="params">(self, lr)</span>:</span></span><br><span class="line">        self.rnncell.w_i2h -= lr * self.grad_w_i2h</span><br><span class="line">        self.rnncell.w_h2h -= lr * self.grad_w_h2h</span><br><span class="line">        self.rnncell.bias -= lr * self.grad_bias</span><br><span class="line">        <span class="keyword">return</span> self.rnncell.w_i2h, self.rnncell.w_h2h, self.rnncell.bias</span><br></pre></td></tr></table></figure><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><p><a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">https://zybuluo.com/hanbingtao/note/541458</a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>ç«™ç‚¹å¯¼èˆª</title>
      <link href="/2018/12/03/navigation/"/>
      <url>/2018/12/03/navigation/</url>
      
        <content type="html"><![CDATA[<h2 id="æœºå™¨å­¦ä¹ "><a href="#æœºå™¨å­¦ä¹ " class="headerlink" title="æœºå™¨å­¦ä¹ "></a>æœºå™¨å­¦ä¹ </h2><ul><li><a href="/2018/09/19/EasyML-1/">æœºå™¨å­¦ä¹ ç®€ä»‹</a></li><li><a href="/2018/09/27/linear-regression/">çº¿æ€§å›å½’</a></li><li><a href="/2018/11/03/logistic-regression/">é€»è¾‘å›å½’</a></li><li><a href="/2018/11/18/neural-network/">äººå·¥ç¥ç»ç½‘ç»œ</a></li><li><a href="/2018/12/28/rnn/">å¾ªç¯ç¥ç»ç½‘ç»œ</a></li><li><a href="/2019/01/19/LSTM/">LSTM</a></li><li><a href="/2019/01/27/attention/">Attentionâ€”â€”æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶</a></li></ul><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li>word2vec</li><li>self attention</li><li>graph attention</li><li>BERT</li><li>ç›®æ ‡æ£€æµ‹</li><li>æ¨èç®—æ³•</li><li>ç”Ÿæˆç½‘ç»œ</li><li>DQN</li><li>â€¦</li></ul>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>äººå·¥ç¥ç»ç½‘ç»œï¼ˆArtificial Neural Networkï¼‰</title>
      <link href="/2018/11/18/neural-network/"/>
      <url>/2018/11/18/neural-network/</url>
      
        <content type="html"><![CDATA[<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>ä¸€ä¸ªä¸‰å±‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹å¦‚ä¸‹ï¼š</p><p><img src="/resource/images/nn.png" alt="nn model"></p><a id="more"></a><p>ç¥ç»ç½‘ç»œå¯åˆ†ä¸ºè¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ï¼Œè¾“å…¥å±‚ä¸€èˆ¬é™¤äº†è¾“å…¥çš„ç‰¹å¾æ•°æ®ä¹‹å¤–ï¼Œè¿˜ä¼šæœ‰ä¸€ä¸ªåå·®é¡¹ï¼ˆbiasï¼‰ã€‚ç¥ç»ç½‘ç»œä¸€èˆ¬ä¼šåŒ…å«ä¸€ä¸ªæˆ–è€…å¤šä¸ªéšè—å±‚ï¼Œéšè—å±‚ä¸€èˆ¬ç”±å¤šä¸ªç¥ç»å…ƒï¼ˆNeural Unitï¼‰æ„æˆï¼Œä¸Šå›¾ä¸­çš„æœ‰ä¸€ä¸ªéšè—å±‚ï¼Œéšè—å±‚ä¸­æœ‰4ä¸ªç¥ç»å…ƒã€‚è¾“å‡ºå±‚æ ¹æ®å…·ä½“ä¸åŒçš„ä»»åŠ¡å¯ä»¥ç”±ç¥ç»å…ƒæˆ–è€…æ™®é€šçš„çº¿æ€§å›å½’ç­‰æ„æˆã€‚</p><h3 id="ç¥ç»å…ƒ"><a href="#ç¥ç»å…ƒ" class="headerlink" title="ç¥ç»å…ƒ"></a>ç¥ç»å…ƒ</h3><p>ç¥ç»å…ƒä¸€èˆ¬ç”±ä¸€ä¸ªçº¿æ€§å›å½’å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆéçº¿æ€§éƒ¨åˆ†ï¼‰æ„æˆï¼Œä¾‹å¦‚ï¼šé€»è¾‘å›å½’å¯ä»¥ä½œä¸ºç¥ç»ç½‘ç»œä¸­çš„ä¸€ç§ç¥ç»å…ƒã€‚</p><p>å¸¸è§çš„æ¿€æ´»å‡½æ•°æœ‰ï¼šsigmoidå‡½æ•°ã€Reluã€tanhç­‰ã€‚</p><h3 id="å‰å‘è®¡ç®—"><a href="#å‰å‘è®¡ç®—" class="headerlink" title="å‰å‘è®¡ç®—"></a>å‰å‘è®¡ç®—</h3><p>è®¾è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚çš„å•å…ƒä¸ªæ•°åˆ†åˆ«ä¸º nï¼Œlï¼Œ kï¼Œåˆ™3å±‚çš„ç¥ç»ç½‘ç»œä¸€å…±æœ‰ $n \cdot l + l \cdot k$ ä¸ªå‚æ•°ã€‚</p><p>$$<br>\begin{aligned}<br>z_2 =&amp; \Theta_1 X \\<br>a_2 =&amp; g(z_2) \\<br>z_3 =&amp; \Theta_2 a_2 \\<br>a_3 =&amp; g(z_3) \\<br>\hat{y} =&amp; a_3 \\<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼ŒX æ˜¯è¾“å…¥çš„ç‰¹å¾å‘é‡ï¼Œ$\hat{y}$ æ˜¯ç¥ç»ç½‘ç»œè¾“å‡ºçš„ç»“æœï¼Œ$\Theta_1$ æ˜¯ä¸€ä¸ª $n \cdot l$ çš„å‚æ•°çŸ©é˜µï¼ˆè¾“å…¥å±‚ä¸ºnï¼Œéšè—å±‚ä¸ºlï¼‰ï¼Œ$\Theta_2$ æ˜¯éšè—å±‚åˆ°è¾“å‡ºå±‚çš„å‚æ•°çŸ©é˜µï¼Œå¤§å°ä¸º $l \cdot k$ï¼Œ$g(z)$ ä¸ºæ¿€æ´»å‡½æ•°ï¼Œè¿™é‡Œä½¿ç”¨sigmoidå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚è¿™é‡Œçš„ $a, z$ éƒ½æ˜¯å‘é‡ï¼Œå‡½æ•° $g(z)$ ä¹Ÿæ˜¯æŒ‡å¯¹å‘é‡ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ åšéçº¿æ€§å˜æ¢ã€‚</p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>ç¥ç»ç½‘ç»œä¸€èˆ¬ä½¿ç”¨äº¤å‰ç†µï¼Œå³ä½¿ç”¨å’Œé€»è¾‘å›å½’ç±»ä¼¼çš„æŸå¤±å‡½æ•°ï¼Œè¾“å‡ºå±‚çš„æ¯ä¸€ä¸ªè¾“å‡ºå•å…ƒæ˜¯ä¸€ä¸ªé€»è¾‘å›å½’æŸå¤±ï¼Œå¹¶ä¸”æ±‚å’Œã€‚</p><p>$$<br>\begin{aligned}<br>loss =  J(\theta) = &amp; \frac{1}{m} \sum_{i=1}^{m} \sum_{i=1}^{K} Cost(\hat{y}^i_k - y^i_k) \\<br>= &amp; -  \frac{1}{m} \sum_{i=1}^{m} \sum_{i=1}^{K} [y^i_k \log{\hat{y}^i_k} + (1- y^i_k) \log{(1 - \hat{y}^i_k)}]<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ï¼ŒK è¾“å‡ºå±‚è¾“å‡ºå•å…ƒä¸ªæ•°ï¼Œ m ä¸ºè®­ç»ƒæ ·æœ¬æ•°ï¼Œ$\hat{y}^i_k$ ä¸ºç¬¬iä¸ªæ ·æœ¬çš„ç¬¬kä¸ªè¾“å‡ºå•å…ƒçš„è¾“å‡ºç»“æœã€‚</p><h2 id="ä¼˜åŒ–ç›®æ ‡"><a href="#ä¼˜åŒ–ç›®æ ‡" class="headerlink" title="ä¼˜åŒ–ç›®æ ‡"></a>ä¼˜åŒ–ç›®æ ‡</h2><p>æ±‚ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„å‚æ•° ${\Theta}$ ã€‚</p><p>$$\min_{\Theta} J(\Theta)$$</p><h2 id="è®¡ç®—æ¢¯åº¦"><a href="#è®¡ç®—æ¢¯åº¦" class="headerlink" title="è®¡ç®—æ¢¯åº¦"></a>è®¡ç®—æ¢¯åº¦</h2><p>ä½¿ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™è®¡ç®—æ¢¯åº¦ï¼Œ$\Theta_2$ çš„æ¢¯åº¦ä¸ºï¼š</p><p>$$<br>\frac{\partial J}{\partial\Theta_2} = \frac{\partial J}{\partial \hat{y}} \frac{\partial \hat{y}}{\partial z_3}   \frac{\partial z_3}{\partial \Theta_2} = (-\frac{y}{\hat{y}} + \frac{1-y}{1-\hat{y}}) (\hat{y}(1-\hat{y})) \cdot a_2 = (\hat{y} - y) \cdot a_2<br>$$</p><p>$\Theta_1$ çš„æ¢¯åº¦ä¸ºï¼š</p><p>$$<br>\frac{\partial J}{\partial\Theta_1} = \frac{\partial J}{\partial \hat{y}}   \frac{\partial \hat{y}}{\partial z_3}   \frac{\partial z_3}{\partial a_2}    \frac{\partial a_2}{\partial z_2}  \frac{\partial z_2}{\partial \Theta_1} = {(\hat{y} - y) \Theta_2 [a_2(1-a_2)]} \cdot X<br>$$</p><p>è¿™å®é™…ä¸Šä¹Ÿå°±æ˜¯åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ç®—æ³•ã€‚ä»¤ $\delta^L = \hat{y} - y$ ï¼Œåˆ™ $\delta^{l-1} = \delta^l \Theta_{l-1} [a_{l-1}(1-a_{l-1})]$ ï¼Œæ¢¯åº¦ $\Delta^l = \delta^{l+1} a_l$ ã€‚</p><p><strong>æ³¨æ„</strong>ï¼šä¸Šé¢ä¸¤ä¸ªå¼å­ä¸­çš„ $\Thetaï¼Œ aï¼Œzï¼Œ \hat{y}$ æŒ‡çš„æ˜¯çŸ©é˜µæˆ–è€…å‘é‡ä¸­çš„å…ƒç´ åˆ†åˆ«æ±‚åå¯¼æ•°ï¼Œä¸Šé¢è¿™ä¹ˆå†™æ˜¯ä¸ºäº†ç®€ä¾¿ã€‚æ±‚å¯¼è¿‡ç¨‹å†™æˆçŸ©é˜µè¿ç®—çš„å½¢å¼ä¹Ÿæ›´æ–¹ä¾¿ï¼Œéœ€æ³¨æ„è¿›è¡Œç›¸åº”çš„è½¬ç½®å˜æ¢ã€‚</p><p>éšç€æ¨¡å‹ç»“æ„è¶Šæ¥è¶Šå¤æ‚ï¼Œæ¯æ¬¡éƒ½å»è®¡ç®—æ¢¯åº¦æ¯”è¾ƒå¤æ‚ï¼Œç°åœ¨å·²ç»æœ‰å¾ˆå¤šæ·±åº¦å­¦ä¹ æ¡†æ¶å¯ä»¥è¿›è¡Œ<strong>è‡ªåŠ¨å¾®åˆ†</strong>è®¡ç®—æ¢¯åº¦ã€‚ä¸‹é¢æˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™æ¥è‡ªå·±è®¡ç®—ä¸€ä¸‹ç¥ç»ç½‘ç»œçš„æ¢¯åº¦ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p><a href="https://github.com/hf136/models/blob/master/ArtificialNeuralNetwork/raw_neural_network.py" target="_blank" rel="noopener">å®Œæ•´ä»£ç </a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">input_size = <span class="number">2</span></span><br><span class="line">hidden_size = <span class="number">5</span></span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆå‚æ•°theta</span></span><br><span class="line">theta1 = np.random.rand(input_size + <span class="number">1</span>, hidden_size)</span><br><span class="line">theta2 = np.random.rand(hidden_size, output_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ·»åŠ åå·®é¡¹</span></span><br><span class="line">ones = np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line">X = np.concatenate((X, ones), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-1</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10001</span>):</span><br><span class="line">    <span class="comment"># å®šä¹‰æ¨¡å‹ï¼Œå‰å‘è®¡ç®—ï¼ˆè¿™é‡Œçš„éšè—å±‚æ²¡æœ‰æ·»åŠ åå·®é¡¹ï¼Œä¹Ÿå¯ä»¥åœ¨æ¯å±‚éšè—å±‚éƒ½åŠ ä¸Šåå·®é¡¹ï¼‰</span></span><br><span class="line">    z2 = X.dot(theta1)</span><br><span class="line">    a2 = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z2))</span><br><span class="line">    z3 = a2.dot(theta2)</span><br><span class="line">    pred_y = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z3))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    loss = - (y * np.log(pred_y) + (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - pred_y)).mean()</span><br><span class="line">    print(<span class="string">'epoch &#123;&#125;, loss &#123;&#125;'</span>.format(epoch, loss))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è¾“å‡ºè®­ç»ƒæ—¶çš„å‡†ç¡®ç‡</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        pred_label = pred_y &gt;= <span class="number">0.5</span></span><br><span class="line">        true_label = y &gt;= <span class="number">0.5</span></span><br><span class="line">        diff = pred_label == true_label</span><br><span class="line">        accuracy = diff.mean()</span><br><span class="line">        print(<span class="string">'accuracy &#123;&#125;'</span>.format(accuracy))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ä½¿ç”¨é“¾å¼æ±‚å¯¼è®¡ç®—æ¢¯åº¦ï¼ˆå’Œåå‘ä¼ æ’­æ˜¯ä¸€è‡´çš„ï¼‰</span></span><br><span class="line">    grad_z3 = pred_y - y</span><br><span class="line">    grad_theta2 = a2.T.dot(grad_z3)</span><br><span class="line">    grad_a2 = grad_z3.dot(theta2.T)</span><br><span class="line">    grad_z2 = grad_a2 * a2 * (<span class="number">1</span> - a2)</span><br><span class="line">    grad_theta1 = X.T.dot(grad_z2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    theta2 -= learning_rate * grad_theta2</span><br><span class="line">    theta1 -= learning_rate * grad_theta1</span><br></pre></td></tr></table></figure><p>é¢„æµ‹ç»“æœï¼š</p><p><img src="https://github.com/hf136/models/raw/master/docs/images/ann_res.png" alt="lr res"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ­£åˆ™åŒ–ï¼ˆregularizationï¼‰</title>
      <link href="/2018/11/17/regularization/"/>
      <url>/2018/11/17/regularization/</url>
      
        <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯æ­£åˆ™åŒ–ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯æ­£åˆ™åŒ–ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯æ­£åˆ™åŒ–ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯æ­£åˆ™åŒ–ï¼Ÿ</h2><p>æ­£åˆ™åŒ–ä¸»è¦çš„ä½œç”¨æ˜¯é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œå…¶åŸç†æ˜¯å¯¹ç½‘ç»œä¸­çš„å‚æ•°è¿›è¡Œæƒ©ç½šï¼ˆçº¦æŸï¼‰ï¼Œé˜²æ­¢ç½‘ç»œæ¨¡å‹ä¸­çš„å‚æ•°è¿‡å¤§è€Œè¿‡äºåå‘æŸä¸€ä¸ªç‰¹å¾ã€‚å¸¸è§çš„æ­£åˆ™åŒ–æœ‰L1å’ŒL2æ­£åˆ™åŒ–ã€‚</p><h2 id="L1æ­£åˆ™åŒ–"><a href="#L1æ­£åˆ™åŒ–" class="headerlink" title="L1æ­£åˆ™åŒ–"></a>L1æ­£åˆ™åŒ–</h2><p>å¯¹æ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ä¸€èˆ¬æ˜¯å°†æ­£åˆ™é¡¹ç›´æ¥åŠ åˆ°æŸå¤±å‡½æ•°åé¢ï¼ŒL1æ­£åˆ™åŒ–æ˜¯æŠŠç½‘ç»œä¸­æ‰€æœ‰çš„å‚æ•°çš„ç»å¯¹å€¼ç›¸åŠ ã€‚</p><p>$$loss_{regularization} = loss + \lambda \sum_{j=1}^{n} |\theta_j|$$</p><p>å…¶ä¸­ $\lambda$ ä¸ºæ­£åˆ™åŒ–ç³»æ•°ï¼Œ$n$ ä¸ºå‚æ•°ä¸ªæ•°ã€‚</p><h2 id="L2æ­£åˆ™åŒ–"><a href="#L2æ­£åˆ™åŒ–" class="headerlink" title="L2æ­£åˆ™åŒ–"></a>L2æ­£åˆ™åŒ–</h2><p>$$loss_{regularization} = loss + \frac{\lambda}{2} \sum_{j=1}^{n} \theta_j^2$$</p><p>å…¶ä¸­ $\lambda$ ä¸ºæ­£åˆ™åŒ–ç³»æ•°ï¼ˆè¿™é‡Œé™¤äº2æ˜¯ä¸ºäº†æ±‚å¯¼æ—¶è®¡ç®—ç®€ä¾¿ï¼‰ï¼Œ$n$ ä¸ºå‚æ•°ä¸ªæ•°ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰</title>
      <link href="/2018/11/03/logistic-regression/"/>
      <url>/2018/11/03/logistic-regression/</url>
      
        <content type="html"><![CDATA[<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>é€»è¾‘å›å½’å®é™…ä¸Šæ˜¯åœ¨çº¿æ€§å›å½’çš„åŸºç¡€ä¸Šåœ¨åŠ ä¸Šä¸€ä¸ªsigmoidå‡½æ•°ï¼ˆéçº¿æ€§å˜æ¢ï¼‰ï¼š</p><p>$$<br>h_\theta(x) = \frac{1}{1 + e^{-\bf{\theta{^T}x}}}<br>$$</p><p>å¯åˆ†å¼€å†™æˆï¼š</p><p>$$<br>\begin{aligned}<br>h_\theta(x) =&amp; g({\bf{\theta{^T} x}}) \\<br>g(z) =&amp; \frac{1}{1 + e^{-z}}<br>\end{aligned}<br>$$</p><p>å…¶ä¸­ $g(z)$ ç§°ä¸ºsigmoidå‡½æ•°ï¼Œå‡½æ•°å›¾åƒä¸ºï¼š</p><p><img src="/resource/images/sigmoid.png" alt="sigmoid image"></p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>$$<br>\begin{aligned}<br>loss =  J(\theta) = &amp; \frac{1}{m} \sum_{i=1}^{m}Cost(h_\theta(x^i) - y^i) \\<br>= &amp; -  \frac{1}{m} [\sum_{i=1}^{m} y^i \log{h_\theta(x^i)} + (1- y^i) \log{(1 - h_\theta(x^i))}]<br>\end{aligned}<br>$$</p><p>é€»è¾‘å›å½’è¾“å‡ºçš„å€¼åœ¨ 0-1 ä¹‹é—´ï¼Œä½¿ç”¨logæŸå¤±ï¼Œå½“æ ‡ç­¾ $y^i=1$ æ—¶ï¼Œé¢„æµ‹ç»“æœ $h_\theta(x^i)$ ä¹Ÿä¸º 1 æ—¶æŸå¤±ä¸º0ï¼Œé¢„æµ‹ç»“æœä¸ 1 ç›¸å·®è¶Šå¤šï¼ŒæŸå¤±è¶Šå¤§ã€‚å½“æ ‡ç­¾ $y^i=0$ æ—¶åŒç†ã€‚</p><h2 id="ä¼˜åŒ–ç›®æ ‡"><a href="#ä¼˜åŒ–ç›®æ ‡" class="headerlink" title="ä¼˜åŒ–ç›®æ ‡"></a>ä¼˜åŒ–ç›®æ ‡</h2><p>æ±‚ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„å‚æ•° $\bf{\theta}$ ã€‚</p><p>$$\min_{\theta} J(\theta)$$</p><h2 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h2><p>æ±‚æŸå¤±å‡½æ•°å…³äºæ¯ä¸€ä¸ªå‚æ•° $\theta_j$ çš„æ¢¯åº¦å¹¶ä¸æ–­è¿­ä»£ã€‚</p><p>$$\theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m}{(h_\theta(x^i) - y^i)x_j^i}$$</p><p>å…¶ä¸­ï¼Œ$x^i$ è¡¨ç¤ºç¬¬iæ¡æ•°æ®ï¼Œ$x_j$ è¡¨ç¤ºç¬¬jä¸ªç‰¹å¾ï¼Œå¯¹åº”çš„å‚æ•°ä¸º $\theta_j$ï¼› è¿™ä¸ªå¼å­å’Œçº¿æ€§å›å½’çš„å®Œå…¨ä¸€è‡´ï¼</p><h2 id="å…·ä½“æ±‚å¯¼è¿‡ç¨‹"><a href="#å…·ä½“æ±‚å¯¼è¿‡ç¨‹" class="headerlink" title="å…·ä½“æ±‚å¯¼è¿‡ç¨‹"></a>å…·ä½“æ±‚å¯¼è¿‡ç¨‹</h2><p>sigmoidå‡½æ•°æ±‚å¯¼ï¼š<br>$$<br>\begin{aligned}<br>g^\prime(z) =&amp; \frac{d}{dz} \frac{1}{1 + e^{-z}} \\<br>=&amp; \frac{1}{(1 + e^{-z})^2} e^{-z} \\<br>=&amp; \frac{1}{1 + e^{-z}} (1 - \frac{1}{1 + e^{-z}}) \\<br>=&amp; g(z)(1-g(z)) \\<br>\end{aligned}<br>$$</p><p>å¯¹æŸå¤±å‡½æ•°æ±‚ $\theta$ çš„å¯¼æ•°ï¼š<br>$$<br>\begin{aligned}<br>J^\prime(\theta_j) =&amp; -\frac{1}{m} \sum_{i=1}^{m} \frac{\partial}{\partial\theta_j} [y^i \log{h_\theta(x^i)} + (1- y^i) \log{(1 - h_\theta(x^i))}] \\<br>=&amp; -\frac{1}{m} \sum_{i=1}^{m} [y \frac{1}{h_\theta(x^i)} - (1-y)\frac{1}{1-h_\theta(x^i)}] \frac{\partial}{\partial\theta_j} g({\bf{\theta{^T} x}}) \\<br>=&amp; -\frac{1}{m} \sum_{i=1}^{m} [y \frac{1}{g({\bf{\theta{^T} x}})} - (1-y)\frac{1}{1-g({\bf{\theta{^T} x}})}] g({\bf{\theta{^T} x}})(1-g({\bf{\theta{^T} x}})) \frac{\partial}{\partial\theta_j} {\bf{\theta{^T} x}} \\<br>=&amp; -\frac{1}{m} \sum_{i=1}^{m} (y(1-g({\bf{\theta{^T} x}})) - (1-y)g({\bf{\theta{^T} x}})) x_j \\<br>=&amp; \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^i) - y) x_j<br>\end{aligned}<br>$$</p><p>å¯¹äºæ›´å¤æ‚çš„æ¨¡å‹ç›´æ¥æ±‚å¯¼æ¯”è¾ƒå›°éš¾ï¼Œç›®å‰æ¯”è¾ƒæµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸€èˆ¬ä½¿ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™è‡ªåŠ¨æ±‚å¯¼ï¼ˆåº”è¯¥è¯´æ˜¯è‡ªåŠ¨å¾®åˆ†ï¼‰ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p><a href="https://github.com/hf136/models/tree/master/LogisticRegression" target="_blank" rel="noopener">å®Œæ•´ä»£ç </a>æ”¾åœ¨äº†GitHubä¸Šï¼Œä¸‹é¢æ˜¯æ ¸å¿ƒçš„ä»£ç ç‰‡æ®µã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰å‚æ•° w å’Œ b</span></span><br><span class="line">theta = np.random.rand(<span class="number">2</span>)</span><br><span class="line">bias = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># å®šä¹‰æ¨¡å‹ï¼Œå‰å‘è®¡ç®—</span></span><br><span class="line">    z = X.dot(theta) + bias</span><br><span class="line">    pred_y = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    loss = - (y * np.log(pred_y) + (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - pred_y)).mean()</span><br><span class="line">    print(<span class="string">'epoch &#123;&#125;, loss &#123;&#125;'</span>.format(epoch, loss))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è®¡ç®—æ¢¯åº¦ï¼ˆæ±‚å¯¼ï¼‰</span></span><br><span class="line">    grad_theta = (pred_y - y).T.dot(X) / y.size</span><br><span class="line">    grad_bias = (pred_y - y).sum() / y.size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    theta -= learning_rate * grad_theta</span><br><span class="line">    bias -= learning_rate * grad_bias</span><br></pre></td></tr></table></figure><p>é¢„æµ‹ç»“æœï¼š</p><p><img src="https://github.com/hf136/models/raw/master/docs/images/logis-reg.png" alt="lr res"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>çº¿æ€§å›å½’ï¼ˆLinear Regressionï¼‰</title>
      <link href="/2018/09/27/linear-regression/"/>
      <url>/2018/09/27/linear-regression/</url>
      
        <content type="html"><![CDATA[<h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><p>$$y={\bf{wx}} +b$$</p><p>å…¶ä¸­ï¼Œ${\bf{w}}$ å’Œ ${\bf{x}}$ éƒ½æ˜¯å‘é‡ï¼Œ ${\bf{w}} = w_1, w_2, â€¦, w_n$ è¡¨ç¤ºè¦å­¦ä¹ çš„æ¨¡å‹å‚æ•°, ${\bf{x}} = x_1, x_2, â€¦, x_n$ è¡¨ç¤ºæ¨¡å‹çš„è¾“å…¥ã€‚</p><h2 id="æŸå¤±å‡½æ•°ï¼ˆä»£ä»·å‡½æ•°ï¼‰"><a href="#æŸå¤±å‡½æ•°ï¼ˆä»£ä»·å‡½æ•°ï¼‰" class="headerlink" title="æŸå¤±å‡½æ•°ï¼ˆä»£ä»·å‡½æ•°ï¼‰"></a>æŸå¤±å‡½æ•°ï¼ˆä»£ä»·å‡½æ•°ï¼‰</h2><p>$$L({\bf{w}}, b) = \frac{1}{2m} \sum_{i=1}^{m}{(y^\prime_i - y_i)^2}$$</p><p>å…¶ä¸­ï¼Œ$m$ è¡¨ç¤ºè®­ç»ƒæ ·æœ¬æ•°ï¼Œ $y^\prime$ è¡¨ç¤ºæ¨¡å‹è¾“å‡ºç»“æœï¼Œ $y$ è¡¨ç¤ºå®é™…ç»“æœã€‚</p><h2 id="ä¼˜åŒ–ç›®æ ‡"><a href="#ä¼˜åŒ–ç›®æ ‡" class="headerlink" title="ä¼˜åŒ–ç›®æ ‡"></a>ä¼˜åŒ–ç›®æ ‡</h2><p>æ±‚ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°çš„å‚æ•° ${\bf{w}}$ å’Œ $b$ ã€‚</p><p>$$\min_{w,b}L({\bf{w}}, b)$$</p><h2 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h2><p>å¯¹æŸå¤±å‡½æ•°æ±‚æ¯ä¸ª $w_j$ å’Œ $b$ çš„åå¯¼æ•°ï¼Œå¹¶é€šè¿‡ä¸‹å¼ä¸æ–­è¿­ä»£å¾—åˆ°è¾ƒä¼˜çš„å‚æ•°ï¼š</p><p>$$w_j := w_j - \alpha \frac{1}{m} \sum_{i=1}^{m}{(y^\prime_i - y_i)x_j}$$</p><p>$$b := b - \alpha \frac{1}{m} \sum_{i=1}^{m}{(y^\prime_i - y_i)}$$</p><p>å…¶ä¸­ï¼Œ $\alpha$ ä¸ºå­¦ä¹ é€Ÿç‡ï¼Œ $\alpha$ åé¢çš„é¡¹ä¸ºåå¯¼æ•°ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p><a href="https://github.com/hf136/models/tree/master/LinearRegression" target="_blank" rel="noopener">å®Œæ•´ä»£ç </a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰å‚æ•° w å’Œ b</span></span><br><span class="line">w = random.random()</span><br><span class="line">b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># å®šä¹‰æ¨¡å‹ï¼Œå‰å‘è®¡ç®—</span></span><br><span class="line">    pred_y = w * x + b</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loss</span></span><br><span class="line">    loss = <span class="number">0.5</span> * np.square(pred_y - y).mean()</span><br><span class="line">    print(<span class="string">'epoch &#123;&#125;, loss &#123;&#125;'</span>.format(epoch, loss))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è®¡ç®—æ¢¯åº¦ï¼ˆæ±‚å¯¼ï¼‰</span></span><br><span class="line">    grad_w = ((pred_y - y) * x).mean()</span><br><span class="line">    grad_b = (pred_y - y).mean()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°å‚æ•°</span></span><br><span class="line">    w -= learning_rate * grad_w</span><br><span class="line">    b -= learning_rate * grad_b</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å‡½æ•°çš„å¯¼æ•°</title>
      <link href="/2018/09/20/math/"/>
      <url>/2018/09/20/math/</url>
      
        <content type="html"><![CDATA[<h2 id="å¸¸è§åŸºæœ¬å‡½æ•°å¯¼æ•°"><a href="#å¸¸è§åŸºæœ¬å‡½æ•°å¯¼æ•°" class="headerlink" title="å¸¸è§åŸºæœ¬å‡½æ•°å¯¼æ•°"></a>å¸¸è§åŸºæœ¬å‡½æ•°å¯¼æ•°</h2><table><thead><tr><th>å¯¼æ•°å</th><th>åŸå‡½æ•°</th><th>å¯¼å‡½æ•°</th></tr></thead><tbody><tr><td>å¸¸å‡½æ•°ï¼ˆå¸¸æ•°ï¼‰</td><td>$y=C$ (Cä¸ºå¸¸æ•°)</td><td>$y^\prime=0$</td></tr><tr><td>å¹‚å‡½æ•°</td><td>$y=x^n$</td><td>$y^\prime=nx^{n-1}$</td></tr><tr><td>æŒ‡æ•°å‡½æ•°</td><td>$y=a^x$</td><td>$y^\prime=a^x\ln x$</td></tr><tr><td></td><td>$y=e^x$</td><td>$y^\prime=e^x$</td></tr><tr><td>å¯¹æ•°å‡½æ•°</td><td>$y=\log_a x$</td><td>$y^\prime=\frac{1}{x\ln a}$</td></tr><tr><td></td><td>$y=\ln x$</td><td>$y^\prime=\frac{1}{x}$</td></tr><tr><td>æ­£å¼¦å‡½æ•°</td><td>$y=\sin x$</td><td>$y^\prime=\cos x$</td></tr><tr><td>ä½™å¼¦å‡½æ•°</td><td>$y=\cos x$</td><td>$y^\prime=-\sin x$</td></tr></tbody></table><h2 id="å¤åˆå‡½æ•°æ±‚å¯¼"><a href="#å¤åˆå‡½æ•°æ±‚å¯¼" class="headerlink" title="å¤åˆå‡½æ•°æ±‚å¯¼"></a>å¤åˆå‡½æ•°æ±‚å¯¼</h2><p>åŸå‡½æ•°ï¼š$y^\prime=f(g(x))$ï¼Œ å…¶ä¸­ $y=f(u)$ï¼Œ $u=g(x)$</p><p>ä½¿ç”¨é“¾å¼æ³•åˆ™æ±‚å¯¼ï¼š$y^\prime = f^\prime(u)u^\prime(x) = f^\prime(g(x))g^\prime(x)$</p><h2 id="å¯¼æ•°çš„å››åˆ™è¿ç®—"><a href="#å¯¼æ•°çš„å››åˆ™è¿ç®—" class="headerlink" title="å¯¼æ•°çš„å››åˆ™è¿ç®—"></a>å¯¼æ•°çš„å››åˆ™è¿ç®—</h2><p>$$(u \pm v)^\prime = u^\prime \pm v^\prime$$</p><p>$$(uv)^\prime = u^\prime v + u v^\prime$$</p><p>$$(\frac{u}{v})^\prime = \frac{u^\prime v - u v^\prime}{v^2}$$</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Math </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æœºå™¨å­¦ä¹ å…¥é—¨â€”â€”ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ</title>
      <link href="/2018/09/19/EasyML-1/"/>
      <url>/2018/09/19/EasyML-1/</url>
      
        <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ</h2><p>æœ‰äººè¯´ï¼Œç°åœ¨çš„äººå·¥æ™ºèƒ½å°±æ˜¯ $ y=ax+b $ ï¼Œè™½ç„¶å¯èƒ½åªæ˜¯å¼€ç©ç¬‘ï¼Œä½†å…¶å®æˆ‘è§‰å¾—è¿™å¥è¯å¾ˆæœ‰é“ç†ã€‚</p><p>æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸ªç»å…¸çš„æˆ¿ä»·é¢„æµ‹é—®é¢˜ã€‚ä¸ºäº†å°†é—®é¢˜å˜å¾—æ›´åŠ ç®€å•ï¼Œæˆ‘ä»¬åªè€ƒè™‘ä¸€ç§å› ç´ ï¼šæˆ¿å­é¢ç§¯ã€‚ä¸‹è¡¨ç»™å‡ºäº†ä¸€ç»„ï¼ˆæ„é€ çš„ï¼‰æ•°æ®ï¼Œæˆ¿å­é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰å’Œå¯¹åº”çš„æˆ¿å­ä»·æ ¼ï¼ˆä¸‡å…ƒï¼‰ã€‚</p><p><img src="/resource/images/lr-1.png" alt="data"></p><p>æˆ‘ä»¬ç›®çš„æ˜¯æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œæ ¹æ®æˆ¿å­é¢ç§¯æ¥é¢„æµ‹å‡ºæˆ¿å­ä»·æ ¼ã€‚åªè¦ä½ è¾“å…¥æˆ¿å­çš„é¢ç§¯ï¼Œç³»ç»Ÿå°±èƒ½é¢„æµ‹å‡ºæˆ¿å­çš„ä»·æ ¼ã€‚æˆ‘ä»¬ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œæˆ¿å­çš„ä»·æ ¼å’Œæˆ¿å­é¢ç§¯å…·æœ‰çº¿æ€§å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥äººä¸ºçš„ç”»å‡ºä¸€æ¡ç›´çº¿ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä½¿ç”¨è¿™æ¡ç›´çº¿æ¥ä½œä¸ºé¢„æµ‹æˆ¿ä»·çš„æ¨¡å‹ã€‚è€Œè¿™æ¡ç›´çº¿å¯ä»¥ä½¿ç”¨ $ y=ax+b $ æ¥è¡¨ç¤ºï¼Œåªè¦æˆ‘ä»¬çŸ¥é“äº†aå’Œbçš„å€¼ï¼Œé€šè¿‡è¾“å…¥æˆ¿å­é¢ç§¯$ x $ï¼Œå°±èƒ½é¢„æµ‹å‡ºæˆ¿ä»·ä»·æ ¼ $ y $ã€‚</p><blockquote><p>å¯¹äºè¿™ä¸ªé—®é¢˜æ¥è¯´ï¼Œæ‰€è°“çš„æœºå™¨å­¦ä¹ å°±æ˜¯ï¼šé€šè¿‡å·²æœ‰çš„æˆ¿ä»·æ•°æ®ï¼Œæœºå™¨å¯ä»¥è‡ªåŠ¨è®¡ç®—ï¼ˆå­¦ä¹ ï¼‰å¾—åˆ°aå’Œbï¼Œè¿™æ ·è¿™ä¸ªé—®é¢˜å°±è§£å†³äº†ã€‚</p></blockquote><p>åœ¨æœºå™¨å­¦ä¹ æ²¡æœ‰å‡ºç°ä¹‹å‰ï¼Œæˆ‘ä»¬æ˜¯å¯ä»¥é€šè¿‡ä¸€äº›äººä¸ºæ–¹å¼æ¥è®¡ç®—å‡ºaå’Œbçš„ã€‚æ¯”å¦‚æˆ‘å…ˆç”»å‡ºä¸‹å›¾çš„ç›´çº¿ï¼Œç„¶åä½¿ç”¨é‡è§’å™¨é‡å‡ºç›´çº¿ä¸xè½´çš„å¤¹è§’ï¼Œå°±èƒ½å¾—åˆ°æ–œç‡ä»è€Œè®¡ç®—å‡ºaï¼Œç„¶ååœ¨ç›´çº¿éšä¾¿æ‰¾ä¸€ä¸ªç‚¹(x1, y1)å¸¦å…¥åˆ°å¼å­ä¸­ï¼Œå°±å¯ä»¥è®¡ç®—å‡ºbï¼›æˆ–è€…ç›´æ¥å¸¦å…¥ä¸¤ä¸ªç‚¹ï¼ˆx1, y1ï¼‰ã€ï¼ˆx2, y2ï¼‰ï¼Œé€šè¿‡è§£æ–¹ç¨‹çš„æ–¹å¼è®¡ç®—å‡º a å’Œ bã€‚</p><p><img src="/resource/images/lr-2.png" alt="line"></p><h2 id="å¦‚ä½•è‡ªåŠ¨å­¦ä¹ å¾—åˆ°aå’Œbï¼Ÿ"><a href="#å¦‚ä½•è‡ªåŠ¨å­¦ä¹ å¾—åˆ°aå’Œbï¼Ÿ" class="headerlink" title="å¦‚ä½•è‡ªåŠ¨å­¦ä¹ å¾—åˆ°aå’Œbï¼Ÿ"></a>å¦‚ä½•è‡ªåŠ¨å­¦ä¹ å¾—åˆ°aå’Œbï¼Ÿ</h2><p>ä¸€èˆ¬çš„åšæ³•æ˜¯ï¼šæˆ‘ä»¬å¯ä»¥å…ˆéšæœºå¾—åˆ°ä¸€ä¸ªaå’Œbçš„å€¼ï¼Œæ¯”å¦‚a=1ï¼Œb=0ï¼Œç„¶ååœ¨ä¸æ–­çš„å»è°ƒæ•´aå’Œbçš„å€¼ï¼Œæœ€ç»ˆå¾—åˆ°æœ€ä¼˜çš„ a å’Œ bã€‚<br>ä¸ºäº†èƒ½å¤Ÿä½¿è®¡ç®—æœºèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å¾—åˆ° a å’Œ bï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¡¡é‡æŒ‡æ ‡ï¼Œé‚£å°±æ˜¯æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰æˆ–è€…ç§°ä½œä»£ä»·å‡½æ•°ï¼ˆcost functionï¼‰ï¼Œå®ƒçš„ä½œç”¨çš„è¡¡é‡æ¨¡å‹çš„å¥½åã€‚</p><h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¹³å‡å¹³æ–¹è¯¯å·®æ¥å½“åšæˆ‘ä»¬çš„æŸå¤±å‡½æ•°ï¼Œå³ï¼šæˆ‘ä»¬æœ‰ m æ¡è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å…¬å¼ $ loss = \frac {1} {m} \sum_{i=0}^m (y_i - y_i^\prime)^2 $ æ¥è®¡ç®—æ¨¡å‹é¢„æµ‹çš„å€¼ $y^\prime$ å’ŒçœŸå®å€¼ $y$ ä¹‹é—´çš„å¹³æ–¹è¯¯å·®ã€‚</p><p>å½“æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®ç‡æ˜¯100%çš„æ—¶å€™ï¼ŒæŸå¤±å‡½æ•°çš„å€¼ç­‰äº0ï¼Œä¹Ÿå°±æ˜¯è¯´æŸå¤±å‡½æ•°çš„ç»“æœè¶Šå°ï¼Œæ¨¡å‹çš„æ•ˆæœè¶Šå¥½ã€‚æœ‰äº†è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬å°±å¯ä»¥çŸ¥é“å“ªäº› a å’Œ b çš„å€¼æ˜¯æ¯”è¾ƒå¥½çš„ï¼Œè¿™æ ·æœºå™¨å°±å¯ä»¥çŸ¥é“å“ªäº› a å’Œ b çš„å€¼æ˜¯æ¯”è¾ƒå¥½çš„äº†ã€‚</p><p>æˆ‘ä»¬å¾ˆå®¹æ˜“æƒ³åˆ°ï¼šæˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰å¯èƒ½çš„ a å’Œ b çš„å€¼éå†ä¸€éï¼Œé€šè¿‡å·²æœ‰çš„æ•°æ®å»è®¡ç®—æŸå¤±å‡½æ•°çš„å€¼ï¼Œå–æŸå¤±å‡½æ•°æœ€å°æ—¶æ‰€å¯¹åº”çš„ a å’Œ b çš„å€¼ï¼Œé‚£é—®é¢˜ä¸å°±è§£å†³äº†å—ï¼Ÿ</p><p>æ˜¯çš„ï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•å¤ªç¬¨äº†ï¼Œa å’Œ b çš„å€¼æ˜¯æœ‰æ— é™å¤šå¯èƒ½çš„ï¼Œè€Œä¸”è®¡ç®—é‡å¤ªå¤§ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜éœ€è¦ä¸€ç§æœ‰æ•ˆçš„å­¦ä¹ æ–¹æ³•ï¼š<strong>æ¢¯åº¦ä¸‹é™</strong>ã€‚</p><h3 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h3><p>ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰å‘¢ï¼Ÿ</p><p>åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæˆ‘ä»¬çš„æŸå¤±å‡½æ•°å®é™…ä¸Šæ˜¯ä¸€ä¸ªäºŒæ¬¡å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•çš„ç†è§£ä¸º a æˆ– b å’Œå¯¹åº”æŸå¤±å‡½æ•°çš„å€¼ä¹‹é—´çš„å…³ç³»å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/resource/images/lr-loss.png" alt="loss"></p><p>åœ¨ä¸Šå›¾ä¸­ï¼Œæ¨ªåæ ‡è¡¨ç¤º a çš„å–å€¼ï¼Œçºµåæ ‡è¡¨ç¤º loss çš„å€¼ã€‚æˆ‘ä»¬å¯ä»¥çŸ¥é“å½“ a=2.3 æ—¶, æŸå¤±å‡½æ•° loss çš„å€¼æœ€å°ï¼Œé‚£å¦‚æœä¸€å¼€å§‹æˆ‘ä»¬éšæœºå¾—åˆ°çš„ a çš„åˆå§‹å€¼æ˜¯1.7æˆ–è€…3.6çš„è¯ï¼Œæ€ä¹ˆæ ·æ‰èƒ½å¿«é€Ÿçš„å¾—åˆ°ä¸€ä¸ªæ¥è¿‘æœ€ä¼˜å€¼2.3çš„å€¼å‘¢ï¼Ÿ</p><blockquote><p>ç­”æ¡ˆæ˜¯ï¼šå¯¼æ•°ï¼ˆåªæœ‰ä¸€ä¸ªå˜é‡æ˜¯å¯¼æ•°ï¼Œåœ¨å¤šå˜é‡ä¸­ä¸ºåå¯¼æ•°ï¼‰ã€‚</p><p>æˆ‘ä»¬å¯ä»¥å‘ç°ï¼šå½“ a &gt; 2.3 æ—¶ï¼Œæ¯”å¦‚è¯´ a = 3.6ï¼Œæ­¤æ—¶ a çš„å¯¼æ•°ï¼ˆåˆ‡çº¿çš„æ–œç‡ï¼‰å¤§äº0ï¼›å½“ a &lt; 2.3 æ—¶ï¼Œæ¯”å¦‚è¯´ a = 1.7ï¼Œæ­¤æ—¶ a çš„å¯¼æ•°å°äº0ï¼›è€Œå½“ a = 2.3 æ—¶ï¼Œa çš„å¯¼æ•°ç­‰äº0ã€‚</p></blockquote><p>å‡è®¾ä¸€å¼€æˆ‘ä»¬éšæœºå¾—åˆ°: a = 3.6ï¼Œé‚£ä¹ˆ a éœ€è¦å‘å·¦ç§»åŠ¨ï¼Œå³è®¡ç®— a çš„å¯¼æ•° $ \nabla_a    $ï¼Œå°±å¯ä»¥çŸ¥é“ a éœ€è¦è°ƒæ•´ç§»åŠ¨çš„æ–¹å‘ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹å…¬å¼å¾—åˆ°æ–°çš„ a å€¼ $a_{new}$ ä¸ºï¼š$$ a_{new}=a_{old} - \alpha\nabla_a $$</p><p>å…¶ä¸­ $\alpha$ æ˜¯ä¸€ä¸ªå¤§äº 0 çš„ç³»æ•°ï¼Œé€šå¸¸ç§°ä½œ<strong>å­¦ä¹ ç‡</strong>ï¼Œæ§åˆ¶ç€ a æ¯ä¸€æ¬¡è°ƒæ•´çš„æ­¥é•¿ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œa æ¯æ¬¡çš„è°ƒæ•´å¦‚æœè¿‡å¤§çš„è¯ï¼Œå¾ˆå®¹æ˜“è°ƒæ•´è¿‡å¤´ï¼›å¦‚æœæ¯æ¬¡çš„è°ƒæ•´è¿‡å°çš„è¯ï¼Œå­¦ä¹ çš„é€Ÿåº¦å°±ä¼šéå¸¸æ…¢ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå­¦ä¹ ç‡å»è°ƒæ•´æ§åˆ¶å­¦ä¹ çš„é€Ÿåº¦ã€‚<br><br><img src="/resource/images/lr-loss2.png" alt="loss"></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç»è¿‡å¤šæ¬¡è¿­ä»£ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¿«é€Ÿå¾—åˆ°ä¸€ä¸ªæ— é™æ¥è¿‘äºæœ€ä¼˜å€¼çš„ $ a_{best}$ ï¼ŒåŒç†ï¼Œb çš„æœ€ä¼˜å€¼ $b_{best}$ ä¹Ÿå¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼å¾—åˆ°ã€‚$$ b_{new}=b_{old} - \alpha\nabla_b $$</p><p>æ¢¯åº¦ä¸‹é™ä¸­ï¼Œ<strong>æ¢¯åº¦</strong>æŒ‡çš„æ˜¯ a å’Œ b çš„å¯¼æ•°ï¼ˆå®é™…ä¸Šæ˜¯åå¯¼æ•°ï¼‰ç»„æˆçš„å‘é‡ï¼š$(\nabla_a, \nabla_b)$ ï¼›<strong>ä¸‹é™</strong>æ˜¯æŒ‡æŸå¤±å‡½æ•°å€¼ loss ä¸æ–­å‡å°çš„è¿‡ç¨‹ã€‚</p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>åœ¨è¿™é‡Œï¼Œæœºå™¨å­¦ä¹ å°±æ˜¯:</p><blockquote><p>åœ¨å·²æœ‰çš„æ•°æ®ï¼ˆè®­ç»ƒæ•°æ®ï¼‰çš„åŸºç¡€ä¸Šï¼Œå…ˆå»ºç«‹ä¸€ä¸ªæ•°å­¦æ¨¡å‹ $y=ax+b$ï¼Œå†å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•° $loss$ï¼Œæœ€åé€šè¿‡æ¢¯åº¦ä¸‹é™çš„æ–¹å¼ä¸æ–­çš„è°ƒæ•´æ¨¡å‹å‚æ•° a å’Œ bï¼Œä½¿æŸå¤±å‡½æ•°çš„å€¼ä¸æ–­å˜å°ï¼Œå¾—åˆ°æœ€ä¼˜çš„å‚æ•° $ a_{best}$ å’Œ $ b_{best}$ çš„è¿‡ç¨‹ã€‚</p></blockquote><p>æ¨å¹¿åˆ°ä¸€èˆ¬çš„æƒ…å†µï¼ˆè€ƒè™‘å¤šç§å½±å“æˆ¿ä»·çš„å› ç´ ï¼‰ï¼Œè¿™é‡Œçš„ $x$ å˜æˆäº†ä¸€ç»„å€¼ $x_1, x_2, â€¦ , x_n$, aä¹Ÿç›¸åº”çš„å˜æˆäº†ä¸€ç»„å€¼ï¼Œä¸ºäº†æ›´åŠ å½¢è±¡ä¸€äº›ï¼Œä¸€èˆ¬æˆ‘ä»¬ä½¿ç”¨ weightï¼ˆæƒé‡ï¼‰çš„é¦–å­—æ¯ $w$ æ¥ä»£æ›¿ a ï¼Œå³ï¼š$w_1, w_2, â€¦ , w_n$ï¼Œè¿™é‡Œçš„çº¿æ€§å›å½’æ¨¡å‹å°±å˜æˆäº†ï¼š$$y=w_1 x_1 + w_2 x_2 + â€¦ w_n x_n + b$$</p><p>åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—æ¯ä¸€ä¸ª $w_i$ çš„åå¯¼æ•°ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™çš„å­¦ä¹ æ–¹æ³•æ¥ä¸æ–­è¿­ä»£æ›´æ–°å¾—åˆ°æœ€ä¼˜çš„ $w$ å€¼ã€‚æˆ‘ä»¬å¯ä»¥å°†ä¸Šé¢çš„å…¬å¼ç®€å†™æˆå‘é‡å†…ç§¯çš„å½¢å¼ï¼š $ y=\vec{w} \cdot \vec{x} + b $</p><h2 id="å†è°ˆè°ˆæ·±åº¦å­¦ä¹ "><a href="#å†è°ˆè°ˆæ·±åº¦å­¦ä¹ " class="headerlink" title="å†è°ˆè°ˆæ·±åº¦å­¦ä¹ "></a>å†è°ˆè°ˆæ·±åº¦å­¦ä¹ </h2><p>æ·±åº¦å­¦ä¹ å¯è°“æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­æœ€â€œæ™ºèƒ½â€çš„åˆ†æ”¯ï¼Œè€Œæ·±åº¦å­¦ä¹ ä¸­æ— è®ºå¤šä¹ˆå¤æ‚çš„æ¨¡å‹éƒ½ç¦»ä¸å¼€ $ y=\vec{w} \cdot \vec{x} + b $ ï¼Œå› ä¸ºå®ƒæ˜¯â€œç¥ç»å…ƒâ€çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚</p><p>ç¥ç»å…ƒä¸€èˆ¬ç”± $ y=\vec{w} \cdot \vec{x} + b $ ï¼ˆçº¿æ€§éƒ¨åˆ†ï¼‰åŠ ä¸Šä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼ˆéçº¿æ€§éƒ¨åˆ†ï¼‰ç»„æˆã€‚</p><p>åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ— è®ºå¤šä¹ˆå¤æ‚çš„æ¨¡å‹å‡ ä¹éƒ½ç¦»ä¸å¼€<strong>ç¥ç»å…ƒ</strong>ï¼Œç¥ç»å…ƒä»¥ä¸åŒçš„â€œç©ºé—´ç»“æ„â€ç»„åˆåœ¨ä¸€èµ·ï¼Œæ„æˆäº†å„ç§å„æ ·çš„å¤æ‚æ¨¡å‹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
